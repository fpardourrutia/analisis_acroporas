---
title: "Corales Lorenzo"
author: "Mau, Fer"
date: "11 de noviembre de 2015"
output: html_document
---

##Panorama General

+ Se seleccionaron los parches donde es factible encontrar colonias de _Acropora sp._ por medio de variables de PR (batimetría, etc). Por lo tanto, se espera que
las variables ambientales observadas en este estudio estén restringidas en cuanto
a su rango real.

+ Luego se exploraron dichos parches, y se seleccionaron los que en realidad tiene cubierta de acrópora para ser muestreados. Éstos se digitalizaron.

+ Utilizando la digitalización de los parches, se obtuvo una muestra aleatoria de
sitios a visitar. La cantidad de sitios (r = 4m) en cada parche se seleccionó de
manera que cubrieran el 10% del mismo. De esta manera, todos los puntos deben caer
exactamente en cada parche del shape (al menos teóricamente.)

+ Por tanto, los sitios/polígonos muestreados no son representativos del arrecife
en que se encuentran, sin embargo, componen en un muestreo _estratificado_ de los
parches con _Acrópora sp._ dentro de cada arrecife.

+ Se observa que los puntos de GPS muchas veces no se encuentran dentro del parche
al que se refieren, y además se sabe que el GPS tiene un error (mayor en agua que
en tierra), por lo que la primera cuestión a resolver es cómo asignar variables
ambientales (de rasters con resolución espacial de 2m) a localizaciones
geográficas aproximadas.

+ Considerar que también hay error humano.

## Primera idea

1. Sacar un búfer (ó ventana, más natural para rasters) de 5m (o 3px, experiencia
de Mau) alrededor de cada punto del GPS, obtenemos los pixeles en la intersección
de ese búfer con algún parche, y sacamos la mediana. Notar que automáticamente se excluyen los puntos donde el búfer no intersecta ningún parche. 

2. Se elige la mediana porque es más robusta ante atípicos que la media, pero para
saber esto con precisión, conviene hacer una simulación: círculos con radio 1m
aparte, 2m aparte, etc, y qué porcentaje de los datos comparten.

3. Hacer pruebas con un GPS en el mar, para saber el error de medición. Sacar el
histograma de errores y obtener un tamaño de búfer apropiado.

## Segunda idea:

1. Segmentar la imagen y usar los superpixeles que coinciden con los puntos para
agregar los pixeles individuales.

Desventaja: no se está arreglando el error si el el punto realmente muestreado
cayó en otro superpixel.

## Tercera idea:

1. Segmentar la imagen.

2. Tomar un búfer más pequeño.

3. Usar las medias de los superpixeles en cada búfer para obtener el valor de
las variables ambientales que se van a asignar al pixel.

Desventaja: como el búfer es pequeño, podría no haber intersección entre los puntos
muestreados realmente y los del GPS (con errores).

## Cuarta idea:

1. Si una variable predice bien la distribución de Acrópora palmata, utilizando
un modelo usual, no podemos descartar que se deba a autocorrelación espacial.

2. 

## Tareas:

1. Mau: hacer las ventanas.

2. Fer: empezar el exploratorio.

```{r, message = FALSE}
library("raster")

# Para leer shapes
library("rgdal")

# Para trabajar con shapes.
#library("rgeos") # es una dependencia de raster

library("plyr")
library("dplyr")
library("tidyr")
library("readr")
library("ggplot2")
library("purrr")
library("stringi")

# Para calcular medianas ponderadas
library("matrixStats")

# Para usar escalamiento multidimensional con TSNE
#library("tsne")

# Para ajustar RandomForest
library("randomForest")

# Para hacer Validación Cruzada espacial
# lo estoy instalando de mi Github: lo tuve que parchar porque está inestable
# library("devtools")
# install_github("fpardourrutia/sperrorest@object-incompatibility")
library("sperrorest")
```

```{r, warning=FALSE, message=FALSE}

# ../ es para regresarse una carpeta del working directory.
dir_datos <- "../../datos_analisis_detallado/"

# # Leyendo raster con las reflectancias del 2010 y del 2011 de manera independiente (imagen satelital)
# brick_reflectancias_2010 <- paste0(dir_datos, "reflectancias_2010/WV2_2010-12-20_Mexico_bref_geo_UTM16N.img") %>%
#   brick()
# brick_reflectancias_2011 <- paste0(dir_datos, "reflectancias_2011/WV2_2011-01-19_Mexico_bref_geo_UTM16N.img") %>%
#   brick()
# 
# # Leyendo los otros rasters:
# raster_batimetria <- paste0(dir_datos, "relieve/batimetria_real_pm_completa1.tif") %>%
#   raster()
# # pendiente: pendiente de máximo cambio de la batimetría
# raster_pendiente <- paste0(dir_datos, "relieve/slope_pm1.tif") %>%
#   raster()
# # aspecto: ángulo del gradiente de la batimetría
# raster_aspecto <- paste0(dir_datos, "relieve/aspect_pm.tif") %>%
#   raster()
# 
# # Con el siguiente comando, revisando las proyecciones, podemos ver que todas son iguales.
# #projection(raster_aspecto) == projection(raster_batimetria)
# 
# # Cortando los rasters del mismo tamaño para hacer un único ladrillo, para cada stack de reflectancias:
# # Todo se reproyectará a la proyección de "raster_pendiente", que engloba a ambos pero es ligeramente menor
# # en extensión que "raster_batimetria" (puesto que son pendientes calculadas.)
# 
# # La extensión de los stacks es la misma que la de "raster_pendiente"
# brick_reflectancias_2010_corregido <- resample(brick_reflectancias_2010, raster_pendiente, "bilinear")
# #extent(stack_reflectancias_2010_corregido) == extent(raster_pendiente)
# 
# brick_reflectancias_2011_corregido <- resample(brick_reflectancias_2011, raster_pendiente, "bilinear")
# #extent(stack_reflectancias_2011_corregido) == extent(raster_pendiente)
# 
# # Recortando "raster_batimetria"
# #projection(raster_batimetria) == projection(raster_pendiente)
# raster_batimetria_recortado <- crop(raster_batimetria, raster_pendiente)
# #extent(raster_batimetria_recortado) == extent(raster_pendiente)
# 
# # Recortando "raster_aspecto"
# #projection(raster_aspecto) == projection(raster_pendiente)
# raster_aspecto_recortado <- crop(raster_aspecto, raster_pendiente)
# #extent(raster_aspecto_recortado) == extent(raster_pendiente)
# 
# # Creando un nuevo brick con las imágenes satelitales del 2010, del 2011 y productos de relieve homologados
# # El brick almacena los datos de una manera más eficiente para el análisis que el stack.
# brick_insumos <- list(
#   subset(brick_reflectancias_2010_corregido, 1:4) %>%
#     unstack(),
#   subset(brick_reflectancias_2011_corregido, 1:4) %>%
#     unstack(),
#   list(
#     raster_batimetria_recortado,
#     raster_pendiente,
#     raster_aspecto_recortado
#     )
#   ) %>%
#   # Simplificar listas
#   flatten() %>%
#   brick()
# 
# # Arreglando los nombres de "brick_insumos"
# names(brick_insumos) <- c(
#   names(brick_reflectancias_2010_corregido)[1:4],
#   names(brick_reflectancias_2011_corregido)[1:4],
#   names(raster_batimetria_recortado),
#   names(raster_pendiente),
#   names(raster_aspecto_recortado)
# )
# 
# writeRaster(brick_insumos, "../../productos/brick_insumos.tif")
# 
# # Los nombres no se escriben en el brick, entonces los guardamos por su cuenta
# saveRDS(names(brick_insumos), "../../productos/names_brick_insumos.RData")

# Leyendo raster de insumos:
brick_insumos <- brick("../../productos/brick_insumos.tif")
names_brick_insumos <- readRDS("../../productos/names_brick_insumos.RData")
names(brick_insumos) <- names_brick_insumos

quartz()
plot(brick_insumos)

# Utilizar la intersección para homologar la imágenes del 2010 con la del 2011 sería un problema de regresión:
# Si A es una matriz de pixeles por bandas (n x 4) para el 2010 y B lo mismo para el 2011, lo que se tendría
# que hacer es encontrar una matriz C (4x$) tal que A + AC = B, o AC = B-A, ésto es un problema de regresión.
```

```{r, warning=FALSE, message=FALSE}

# Shape con buffers alrededor de cada punto del GPS, correspondientes a un sitio
# estimado de muestreo de acróporas.
sitios_estimados_acropora_sf <- readOGR(dsn = paste0(dir_datos, "2014_sitios_estimados_acropora"))
plot(sitios_estimados_acropora_sf[1:10,])

# Obteniendo el shape de parches de acrópora ajustados para intersectarlo con los con sitios estimados, y de esta manera, corregir parcialmente el error de GPS.
parches_acropora_ajustados_sh <- readOGR(dsn = paste0(dir_datos, "2014_parches_acropora_ajustados"))
#plot(parches_acropora_ajustados_sh[1:5,])
```

```{r, warning=FALSE, message=FALSE}
# Obteniendo la intersección de ambos shapefiles.

# Comprobando proyecciones:
projection(parches_acropora_ajustados_sh) == projection(sitios_estimados_acropora_sf)
# Una es en UTM y otra en longlat, nos quedamos con UTM porque es la del brick.

sitios_estimados_acropora_sf_utm <- spTransform(sitios_estimados_acropora_sf, projection(parches_acropora_ajustados_sh))
projection(parches_acropora_ajustados_sh) == projection(sitios_estimados_acropora_sf_utm)

# Intersectando ambos shapes, byid = TRUE hace que no se haga un polígono gigante con
# todas las intersecciones, sino varios polígonos pequeños
# raster::intersect difiere de rgeos::gintersect en que preserva data.
intersecciones_parches_sitios_estimados <- raster::intersect(parches_acropora_ajustados_sh, sitios_estimados_acropora_sf_utm)

# Ploteando parches, primero se restringe el extent (primer shape) y luego se plotean
# de los otro shapes los objetos que quepan en dicho extent.

plot(extent(intersecciones_parches_sitios_estimados[1:5,]))
plot(intersecciones_parches_sitios_estimados, col = 'red', add = TRUE)
plot(sitios_estimados_acropora_sf_utm, add = TRUE)
plot(parches_acropora_ajustados_sh, add = TRUE)
# Tudo bem

# Es más eficiente extraer del brick primero lo correspondiente a los parches y
# reextraer de los buffers, porque se evita el problema combinatorio de parches
# vs buffers.
```

```{r, warning=FALSE, message=FALSE}
# # Extrayendo del brick las variables correspondientes cada elemento en el shape
# # de intersecciones, por pixel.
# variables_raster_intersecciones_df <- raster::extract(brick_insumos,
#   intersecciones_parches_sitios_estimados,
#   method = "simple", cellnumbers = TRUE, df = TRUE, weights = TRUE)
# glimpse(variables_raster_intersecciones_df)
# 
# # weights es una variable que a cada pixel le asocia la proporción que le corresponde
# # del polígono considerado, por lo que siempre suman 1 por polígono.
# 
# # Algunos resúmenes:
# variables_raster_intersecciones_df %>%
#   group_by(ID) %>%
#   tally() %>%
#   View()
# 
# variables_raster_intersecciones_df %>%
#   group_by(ID) %>%
#   summarise(
#     uno = sum(weight)
#   ) %>%
#   View()
# 
# # Extrayendo para 2 intersecciones y comparando:
# raster::extract(brick_insumos,
#   intersecciones_parches_sitios_estimados[c(1,125),],
#   method = "simple", cellnumbers = TRUE, df = TRUE, weights = TRUE) %>%
#   View()
# # Todo bien, salen en orden.
#
# Haciendo el join de "variables_raster_intersecciones_df" con los datos de
# "intersecciones_parches_sitios_estimados" y extrayendo atributos necesarios:

# df_pixeles_desglosados <- variables_raster_intersecciones_df %>%
#   inner_join(intersecciones_parches_sitios_estimados@data %>%
#       mutate(
#         ID = 1:nrow(.)
#       ), by = "ID")
# glimpse(df_pixeles_desglosados)
#saveRDS(df_pixeles_desglosados, "../../productos/df_pixeles_desglosados.RData")

df_pixeles_desglosados <-readRDS("../../productos/df_pixeles_desglosados.RData")

# Viendo que cada ID corresponda a un Punto
df_pixeles_desglosados %>%
  group_by(ID, Punto) %>%
  tally() %>%
  nrow()

df_pixeles_desglosados$Punto %>%
  unique() %>%
  length()
# Perfecto!

# Revisando que cada pixel tenga al menos variables satelitales del 2010 o del 2011:
df_pixeles_desglosados %>%
  filter(
    !is.na(WV2_2010.12.20_Mexico_bref_geo_UTM16N.1) |
      !is.na(WV2_2011.01.19_Mexico_bref_geo_UTM16N.1)
  ) %>%
  nrow()

nrow(df_pixeles_desglosados)
# Perfecto
```

```{r, warning=FALSE, message=FALSE}
# Creando el DF de trabajo para el 2010
# df_trabajo_2010 <- df_pixeles_desglosados %>%
#   filter(!is.na(WV2_2010.12.20_Mexico_bref_geo_UTM16N.1)) %>%
#   select(
#     ID,
#     WV2_2010_1 = WV2_2010.12.20_Mexico_bref_geo_UTM16N.1,
#     WV2_2010_2 = WV2_2010.12.20_Mexico_bref_geo_UTM16N.2,
#     WV2_2010_3 = WV2_2010.12.20_Mexico_bref_geo_UTM16N.3,
#     WV2_2010_4 = WV2_2010.12.20_Mexico_bref_geo_UTM16N.4,
#     batimetria = batimetria_real_pm_completa1,
#     pendiente = slope_pm1,
#     aspecto = aspect_pm,
#     peso = weight,
#     punto = Punto,
#     parche = Parche,
#     arrecife = Arrecife,
#     latitud = Lat,
#     longitud = Long,
#     profundidad_media_m = Av_depth_m,
#     cobertura_acropora = Acropora_c
#   ) %>%
#   mutate(
#     punto = as.character(punto) %>%
#       tolower(),
#     parche = as.character(parche) %>%
#       tolower(),
#     arrecife = as.character(arrecife) %>%
#       tolower(),
#     # pesos enteros para calcular medianas.
#     peso_entero = 10^9 * peso
#   ) %>%
#   # Calculando tabla por polígono
#   ddply(.(ID), function(x){
#     
#       # se nombran las variables porque se usará ldply y se quiere tener el .id
#       variables_stack <- c(
#         "WV2_2010_1" = "WV2_2010_1",
#         "WV2_2010_2" = "WV2_2010_2", # Muy correlacionada con WV2_2010_1
#         "WV2_2010_4" = "WV2_2010_4",
#         "batimetria" = "batimetria",
#         "pendiente" = "pendiente",
#         "aspecto" = "aspecto"
#       )
#       
#       # Calculando resúmenes por variable para cada polígono.
#       resumenes_poligono <- ldply(variables_stack, function(variable,x){
#         # Obteniendo los valores de cada variable de una manera un tanto rara,
#         # pues no se puede hacer x$variable pues "variable" es una variable
#         valores <- x[[variable]]
#         pesos <- x$peso_entero
#         
#         resumenes_variable <-data_frame(
#           media =  mean(valores, na.rm = TRUE),
#           media_ponderada = weighted.mean(valores, pesos, na.rm = TRUE),
#           mediana = median(valores, na.rm = TRUE),
#           mediana_ponderada = weightedMedian(valores, pesos, na.rm = TRUE),
#           sd = sd(valores, na.rm = TRUE),
#           sd_ponderada = weightedSd(valores, pesos, na.rm = TRUE)
#         )
#         return(resumenes_variable)
#       }, x) %>%
#         gather(resumen, valor, -.id) %>%
#         # Creando títulos
#         transmute(
#           titulo = paste0(.id, "_", resumen),
#           valor = valor
#         ) %>%
#         # Acomodando tabla
#         spread(titulo, valor)
#       
#       # Creando tabla final para el polígono correspondiente
#       tabla_poligono <- cbind(
#         data_frame(
#           punto = x$punto[1],
#           parche = x$parche[1],
#           arrecife = x$arrecife[1],
#           latitud = x$latitud[1],
#           longitud = x$longitud[1],
#           profundidad_media_m = x$profundidad_media_m[1],
#           cobertura_acropora = x$cobertura_acropora[1]
#         ),
#         resumenes_poligono
#       )
#     })
# saveRDS(df_trabajo_2010, "../../productos/df_trabajo_2010.RData")
df_trabajo_2010 <- readRDS("../../productos/df_trabajo_2010.RData")

# comprobando número de polígonos para el 2010.
nrow(df_trabajo_2010)

df_pixeles_desglosados %>%
  filter(!is.na(WV2_2010.12.20_Mexico_bref_geo_UTM16N.1)) %>%
  group_by(ID) %>%
  tally() %>%
  nrow()
# bien!

# Y el DF de trabajo para el 2011
# df_trabajo_2011 <- df_pixeles_desglosados %>%
#   filter(!is.na(WV2_2011.01.19_Mexico_bref_geo_UTM16N.1)) %>%
#   select(
#     ID,
#     WV2_2011_1 = WV2_2011.01.19_Mexico_bref_geo_UTM16N.1,
#     WV2_2011_2 = WV2_2011.01.19_Mexico_bref_geo_UTM16N.2,
#     WV2_2011_3 = WV2_2011.01.19_Mexico_bref_geo_UTM16N.3,
#     WV2_2011_4 = WV2_2011.01.19_Mexico_bref_geo_UTM16N.4,
#     batimetria = batimetria_real_pm_completa1,
#     pendiente = slope_pm1,
#     aspecto = aspect_pm,
#     peso = weight,
#     punto = Punto,
#     parche = Parche,
#     arrecife = Arrecife,
#     latitud = Lat,
#     longitud = Long,
#     profundidad_media_m = Av_depth_m,
#     cobertura_acropora = Acropora_c
#   ) %>%
#   mutate(
#     punto = as.character(punto) %>%
#       tolower(),
#     parche = as.character(parche) %>%
#       tolower(),
#     arrecife = as.character(arrecife) %>%
#       tolower(),
#     # pesos enteros para calcular medianas.
#     peso_entero = 10^9 * peso
#   ) %>%
#   # Calculando tabla por polígono
#   ddply(.(ID), function(x){
#     
#       # se nombran las variables porque se usará ldply y se quiere tener el .id
#       variables_stack <- c(
#         "WV2_2011_1" = "WV2_2011_1",
#         "WV2_2011_2" = "WV2_2011_2", # Muy correlacionada con WV2_2011_1
#         "WV2_2011_3" = "WV2_2011_3", # Muy correlacionada con WV2_2011_1
#         "WV2_2011_4" = "WV2_2011_4",
#         "batimetria" = "batimetria",
#         "pendiente" = "pendiente",
#         "aspecto" = "aspecto"
#       )
#       
#       # Calculando resúmenes por variable para cada polígono.
#       resumenes_poligono <- ldply(variables_stack, function(variable,x){
#         # Obteniendo los valores de cada variable de una manera un tanto rara,
#         # pues no se puede hacer x$variable pues "variable" es una variable
#         valores <- x[[variable]]
#         pesos <- x$peso_entero
#         
#         resumenes_variable <-data_frame(
#           media =  mean(valores, na.rm = TRUE),
#           media_ponderada = weighted.mean(valores, pesos, na.rm = TRUE),
#           mediana = median(valores, na.rm = TRUE),
#           mediana_ponderada = weightedMedian(valores, pesos, na.rm = TRUE),
#           sd = sd(valores, na.rm = TRUE),
#           sd_ponderada = weightedSd(valores, pesos, na.rm = TRUE)
#         )
#         
#         return(resumenes_variable)
#       }, x) %>%
#         gather(resumen, valor, -.id) %>%
#         # Creando títulos
#         transmute(
#           titulo = paste0(.id, "_", resumen),
#           valor = valor
#         ) %>%
#         # Acomodando tabla
#         spread(titulo, valor)
#       
#       # Creando tabla final para el polígono correspondiente
#       tabla_poligono <- cbind(
#         data_frame(
#           punto = x$punto[1],
#           parche = x$parche[1],
#           arrecife = x$arrecife[1],
#           latitud = x$latitud[1],
#           longitud = x$longitud[1],
#           profundidad_media_m = x$profundidad_media_m[1],
#           cobertura_acropora = x$cobertura_acropora[1]
#         ),
#         resumenes_poligono
#       )
#     })
# 
# # Comprobando número de polígonos totales
# nrow(df_trabajo_2011)
# 
# df_pixeles_desglosados %>%
#   filter(!is.na(WV2_2011.01.19_Mexico_bref_geo_UTM16N.1)) %>%
#   group_by(ID) %>%
#   tally() %>%
#   nrow()
# # bien!
# 
# # Y la cantidad de registros en la unión:
# nrow(df_trabajo_2010) + nrow(df_trabajo_2011) - nrow(df_trabajo_2010 %>%
#     inner_join(df_trabajo_2011, by = "ID"))
# 
# # Si usamos el df del 2011, sólo ganamos 45 nuevos puntos de 925, por lo tanto,
# # no vale la pena el esfuerzo
# nrow(df_trabajo_2011) - nrow(df_trabajo_2010 %>%
#     inner_join(df_trabajo_2011, by = "ID"))
# 
# df_pixeles_desglosados %>%
#   group_by(ID) %>%
#   tally() %>%
#   nrow()
# # perfecto! Se puede comenzar con los análisis
```

```{r, warning=FALSE, message=FALSE}

# Calculando la correlación entre las variables de interés
correlaciones_variables <- df_trabajo_2010 %>%
  filter(complete.cases(.)) %>%
  select(
    latitud,
    longitud,
    profundidad_media_m,
    cobertura_acropora,
    aspecto_media:WV2_2010_4_sd_ponderada
  ) %>%
  cor() %>%
  as_data_frame() %>%
  mutate(
    variable_1 = colnames(.)
  ) %>%
  select(
    variable_1,
    everything()
  ) %>%
  gather(
    key = variable_2, value = correlacion, latitud:WV2_2010_4_sd_ponderada
  )

# Mapa de calor de las correlaciones
ggplot(correlaciones_variables,
  aes(x = variable_1, y = variable_2, fill = correlacion)) +
  geom_tile() +
  scale_fill_gradient2() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
# Podemos ver un patrón muy interesante. Sólo necesitamos quedarnos
# con lo siguiente:
# 1. Por variable, con una medida de tendencia central y una de dispersión.
# 2. Sólo una de las variables WV2_2010_1:WV2_2010_2:

df_trabajo_2010_variables_selectas <- df_trabajo_2010 %>%
  mutate(
    # Categorizando cobertura de acrópora por cuantiles
    cat_cobertura_acropora_2 = cut(cobertura_acropora,
      breaks = quantile(cobertura_acropora, probs = c(0, 0.5, 1)),
      include.lowest = TRUE),
    
    cat_cobertura_acropora_4 = cut(cobertura_acropora,
      breaks = quantile(cobertura_acropora, probs = seq(0, 1, 0.25)),
      include.lowest = TRUE),
    
    # Para validación cruzada espacial
    parche = as.factor(parche),
    arrecife = as.factor(arrecife),
    
    cat_latitud_4 = cut(latitud,
      breaks = quantile(latitud, probs = seq(0, 1, 0.25)),
      include.lowest = TRUE),

    cat_latitud_5 = cut(latitud,
      breaks = quantile(latitud, probs = seq(0, 1, 0.2)),
      include.lowest = TRUE),

    cat_latitud_10 = cut(latitud,
      breaks = quantile(latitud, probs = seq(0, 1, 0.1)),
      include.lowest = TRUE)
    
  ) %>%
  # Para plotear arrecifes en orden de latitud
  group_by(arrecife) %>%
    mutate(
      latitud_media_arrecife = mean(latitud)
    ) %>%
  ungroup() %>%
  select(
    ID,
    
    # VC espacial
    parche,
    arrecife,
    latitud_media_arrecife,
    cat_latitud_4,
    cat_latitud_5,
    cat_latitud_10,
    
    # Variables de salida
    cobertura_acropora,
    cat_cobertura_acropora_2,
    cat_cobertura_acropora_4,
    
    # Variables de entrada
    latitud,
    longitud,
    profundidad_media_m,
    dplyr::contains("media_ponderada"),
    dplyr::contains("sd_ponderada"),
    -dplyr::contains("WV2_2010_2"),
    -dplyr::contains("WV2_2010_3")
  ) %>%
  filter(complete.cases(.))
```
  
```{r, warning=FALSE, message=FALSE}
# Análisis exploratorio

df_plot_2010 <- df_trabajo_2010_variables_selectas %>%
  gather(llave, valor, latitud:WV2_2010_4_sd_ponderada)
glimpse(df_plot_2010)

# Perfilando las variables ambientales por arrecife:
ggplot(data = df_plot_2010,
  aes(x = reorder(arrecife, latitud_media_arrecife), y = valor)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(alpha = 0.3, size = 0.5) +
  facet_wrap(~llave, scales = "free", ncol = 5) +
  theme(axis.text.x = element_text(
    size = 5,
    angle = 90,
    hjust = 1)
    )
# Se ve que Limones tiene densidades únicas en varias variables. Por ejemplo,
# WV2_2010_1/4_media_ponderada o WV2_2010_1_sd_ponderada. Esto es importante
# porque puede justificar el hecho que cuando no se entrena con datos de limones,
# sube mucho el error de predicción para este arrecife, y apoya que nos quedemos con
# una VC que imponga

ggplot(data = df_plot_2010, aes(x = valor, y = cobertura_acropora)) +
  geom_point(alpha = 0.01) +
  geom_smooth() +
  facet_wrap(~llave, scales = "free", ncol = 2) +
  ylim(0, 70)
# Las tendencias son muy suaves, casi nulas, para las variables que puedieran
# presentarlas.

ggplot(data = df_plot_2010, aes(x = cobertura_acropora, y = valor)) +
  geom_point(alpha = 0.01) +
  geom_smooth() +
  facet_wrap(~llave, scales = "free", ncol = 2)
# Aquí se aprecia mejor la tendencia en latitud y longitud, si en aspecto
# hay algo, es muy débil para notarlo. Es decir, latitud y longitud son nuestras
# mejores variables.

#  Ploteando los sitios por arrecife:
ggplot(data = df_trabajo_2010_variables_selectas,
  aes(x = longitud, y = latitud, colour = arrecife)) +
  geom_point()

# Cobertura continua
ggplot(data = df_trabajo_2010_variables_selectas,
  aes(x = longitud, y = latitud, colour = cobertura_acropora)) +
  geom_point(alpha = 0.5) +
  scale_color_gradientn(colours = rainbow(5))
# Parece confetti, se espera que ni la latitud y longitud solas expliquen bien la
# cobertura de A. palmata

# Cobertura discretizada a 2 clases
ggplot(data = df_trabajo_2010_variables_selectas, aes(x = longitud, y = latitud, colour = cat_cobertura_acropora_2)) +
  geom_point(alpha = 0.5)
# Parece confetti, se espera que ni la latitud y longitud solas expliquen bien la
# cobertura de A. palmata

# No se aprecian tendencias lineales significativas, igual y las variables, en su
# conjunto, y no suponiendo tendencias lineales, explican mejor la cobertura de
# A pal.

# Ahora perfilando las distintas variables por la categorización de la cobertura
# de acrópora:

ggplot(data = df_plot_2010, aes(x = cat_cobertura_acropora_2, y = valor)) +
  geom_boxplot() +
  geom_jitter(alpha = 0.03) +
  facet_wrap(~llave, scales = "free", ncol = 2)
# Se ven tendencias en "latitud", "longitud" y "aspecto_media_ponderada"

ggplot(data = df_plot_2010, aes(x = cat_cobertura_acropora_4, y = valor)) +
  geom_boxplot() +
  geom_jitter(alpha = 0.03) +
  facet_wrap(~llave, scales = "free", ncol = 2)
# Se ven tendencias en "latitud", "longitud" y "aspecto_media_ponderada"
```

```{r, warning=FALSE, message=FALSE}
# Clustering de variables ambientales, para ver si una validación cruzada espacial
# puede ser "injusta" con el modelo en ciertos folds (al no darle los insumos
# adecuados)

# df_trabajo_2010_kmeans <- df_trabajo_2010_variables_selectas %>%
#   select(
#     aspecto_media_ponderada:WV2_2010_4_sd_ponderada
#   ) %>%
#   # Para estandarizar datos
#   base::scale() %>%
#   as_data_frame()
# 
# # K-medias
# set.seed(12345)
# 
# # Haciendo la gráfica de codo para obtener el número óptimo de clusters:
# df_grafica_codo <- ldply(1:500, function(i){
#   clustering <- kmeans(df_trabajo_2010_kmeans,
#     centers = i,
#     iter.max = 50,
#     nstart = 25)
#   resultado <- data_frame(
#     num_clusters = i,
#     withinss = clustering$tot.withinss
#     )
#   return(resultado)
# })
# 
# ggplot(data = df_grafica_codo, aes(x = num_clusters, y = withinss)) +
#   geom_line()
# # Esto va a ser un análisis en sí mismo porque la gráfica de codo no me dice mucho.

# matriz_distancias <- df_trabajo_2010_variables_selectas %>%
#   select(
#     aspecto_media_ponderada:WV2_2010_4_sd_ponderada
#   ) %>%
#   # Para estandarizar datos
#   base::scale() %>%
#   dist()

# Creo que clustering Jerárquico ni T-SNE tienen sentido porque
# se basan en distancias entre sitios, y eso creo que es raro considerando la naturaleza de las variables.

# # Clustering Jerárquico. Como con vecino más lejano me salía un cluster muy grande,
# # mejor uso Ward para minimizar within SST
# clustering <- hclust(matriz_distancias, method = "ward.D")
# plot(clustering, hang = -1)
# 
# df_trabajo_2010_grupos_hclust <- df_trabajo_2010_variables_selectas %>%
#   mutate(
#     grupo =  cutree(clustering, h = 25) %>%
#       as.character()
#   )
# 
# df_trabajo_2010_grupos_hclust %>%
#   group_by(grupo) %>%
#   tally()
# 
# ggplot(data = df_trabajo_2010_grupos_hclust,
#   aes(x = longitud,
#     y = latitud,
#     colour = grupo)) +
#   geom_point(alpha = 0.5) +
#   facet_grid(~grupo)
# Jajaja no sale nada
  
# # T-SNE
# tsne_variables_ambientales <- tsne(matriz_distancias, perplexity = 100, max_iter = 2000) %>%
#   as_data_frame() %>%
#   mutate(
#     arrecife = df_trabajo_2010_variables_selectas$arrecife
#   )
# 
# ggplot(tsne_variables_ambientales,
#   aes(x = V1, y = V2, colour = arrecife)) +
#   geom_point()
# # T-SNE no me sirve porque quiero distinguir entre si un arrecife está lejos
# # de otros, no cerca.
```

```{r, warning=FALSE, message=FALSE}
# Ajuste de primeros modelos predictivos:
# 1. Random Forest, sin tomar en cuenta autocorrelación espacial.
# 2. Usando todas las variables, y luego quitando latitud y longitud
# 3. Usando como variable de salido: "cobertura_acropora"" (regresión),
# "cat_cobertura_acropora_2" y "cat_cobertura_acropora_4" (clasificación).

set.seed(12345)

# En "df_trabajo_2010_variables_selectas" ya se filtraron registros con NA's
y_regresion <- df_trabajo_2010_variables_selectas %>%
  '$'(., cobertura_acropora)

y_clasificacion_2 <- df_trabajo_2010_variables_selectas %>%
  '$'(., cat_cobertura_acropora_2)

y_clasificacion_4 <- df_trabajo_2010_variables_selectas %>%
  '$'(., cat_cobertura_acropora_4)

# Primer round: todas las variables vs "y_regresion", "y_clasificacion_2" y
# "y_clasificacion_4"

x1 <- df_trabajo_2010_variables_selectas %>%
  select(
    latitud:WV2_2010_4_sd_ponderada
  )
glimpse(x1)

# No explica mucho para regresión
rf_1_regresion <- randomForest(x = x1, y = y_regresion, importance = TRUE)
  
rf_1_clasificacion_2 <- randomForest(x = x1, y = y_clasificacion_2,
  importance = TRUE)
# Tasa de éxito del ~65%, mucho mejor.

varImpPlot(rf_1_clasificacion_2)
# Longitud y latitud son las más importantes, hay que ver qué onda si hacemos
# validación cruzada espacial.

rf_1_clasificacion_4 <- randomForest(x = x1, y = y_clasificacion_4,
  importance = TRUE)
# Tasa de éxito del ~45%, por lo que funciona mejor para 2 clases.

# Seleccionando otras variables:

# x1 sin latitud ni longitud
x2 <- df_trabajo_2010_variables_selectas %>%
  select(
    profundidad_media_m:WV2_2010_4_sd_ponderada
  )
glimpse(x2)

rf_2_clasificacion_2 <- randomForest(x = x2, y = y_clasificacion_2,
  importance = TRUE)
varImpPlot(rf_2_clasificacion_2)
# Tasa de éxito de ~63%, no baja mucho!

# obteniendo las variables más importantes en varias corridas del rf anterior:
df_variables_importantes <- ldply(1:100, function(i, x2, y_clasificacion_2){
  # Ajustando un Random Forest:
  rf_aux <- randomForest(x = x2, y = y_clasificacion_2, importance = TRUE)
  
  # Calculando las importancias de las variables:
  importancia_variables_aux <- varImpPlot(rf_aux) %>%
    as.matrix()
  nombres_variables <- rownames(importancia_variables_aux)
  
  # Generando data frame con las 5 variables más importantes, en órden, por tipo
  # de prueba:
  variables_importantes_exactitud_df <- importancia_variables_aux %>%
    as_data_frame() %>%
    mutate(
      variable = nombres_variables
    ) %>%
    arrange(desc(MeanDecreaseAccuracy)) %>%
    head(5) %>%
    transmute(
      posicion_exactitud = 1:nrow(.),
      variable_exactitud = variable
    )
  
    variables_importantes_gini_df <- importancia_variables_aux %>%
    as_data_frame() %>%
    mutate(
      variable = nombres_variables
    ) %>%
    arrange(desc(MeanDecreaseGini)) %>%
    head(5) %>%
    transmute(
      posicion_gini = 1:nrow(.),
      variable_gini = variable
    )
    
    df_resultado <- variables_importantes_exactitud_df %>%
      cbind(variables_importantes_gini_df) %>%
      mutate(
        corrida = i
      ) %>%
      select(
        corrida,
        everything()
      )

    return(df_resultado)
  
}, x2, y_clasificacion_2)

variables_importantes_gini <- df_variables_importantes %>%
  group_by(posicion_gini, variable_gini) %>%
  tally() %>%
  arrange(posicion_gini, desc(n))

variables_importantes_exactitud <- df_variables_importantes %>%
  group_by(posicion_exactitud, variable_exactitud) %>%
  tally() %>%
  arrange(posicion_exactitud, desc(n))

# Utilizando las variables más importantes de acuerdo a varias corridas del RF anterior:

# - WV2_2010_1_sd_ponderada
# - WV2_2010_4_sd_ponderada
# - aspecto_media_ponderada
# - pendiente_sd_ponderada
# - batimetria_media_ponderada
# - WV2_2010_4_media_ponderada

x3 <- df_trabajo_2010_variables_selectas %>%
  select(
    WV2_2010_1_sd_ponderada,
    WV2_2010_4_sd_ponderada,
    aspecto_media_ponderada,
    pendiente_sd_ponderada,
    batimetria_media_ponderada,
    WV2_2010_4_media_ponderada
  )
glimpse(x3)

rf_3_clasificacion_2 <- randomForest(x = x3, y = y_clasificacion_2,
  importance = TRUE)
varImpPlot(rf_3_clasificacion_2)
# Tasa de éxito ~62.5%. Nos quedamos con esas variables, por ahora.
```

```{r, warning=FALSE, message=FALSE}
## Validación cruzada espacial

# # Explorando las variables naturales que podrían ser factores para la VC espacial
# df_trabajo_2010_variables_selectas %>%
#   group_by(parche) %>%
#   tally() %>%
#   arrange(desc(n)) %>%
#   View()
# # Son muy poco homogéneos los parches en cantidad de puntos, por ello, se debe
# # hacer el promedio _ponderado_ de los errores de CV para calcular el error CV.
# # Pero esto es un problema que puede tender a inflar el error de CV: suponer que
# # se tienen 100 datos y dos particiones, de 90 y 10 datos respectivamente.
# # Si hacemos lo anterior, entrenamos con 90, predecimos con 10 y esta estimación
# # con un modelo "bien" ajustado pesa poco, pero la contraria: entrenar con 10 y
# # predecir con 90 es una estimación con un modelo mal ajustado que pesa mucho.
# 
# df_trabajo_2010_variables_selectas %>%
#   group_by(arrecife) %>%
#   tally() %>%
#   arrange(desc(n)) %>%
#   View()
# # También muy poco uniformes.
# 
# # Generando la partición espacial del conjunto de datos y visualizándola
# kfolds_kmeans <- partition.kmeans(df_trabajo_2010_variables_selectas,
#   coords = c("latitud", "longitud"),
#   nfold = 10,
#   repetition = 1:1,
#   seed1 = 12345,
#   balancing.steps = 150)
# plot(kfolds_kmeans, df_trabajo_2010_variables_selectas,
#   coords = c("latitud","longitud"))
# # Usando K-means CV tampoco da k-folds del mismo tamaño...

# Mejor usaré cuartiles, quintiles y deciles de latitud.
```

```{r, warning=FALSE, message=FALSE}

# Creando la fórmula:
formula <- paste0("cat_cobertura_acropora_2 ~ ",
  colnames(
    df_trabajo_2010_variables_selectas %>%
      select(
        aspecto_media_ponderada:WV2_2010_4_sd_ponderada
        )
  ) %>%
  paste0(collapse = " + ")) %>%
  as.formula()

### CV con quintiles

# Haciendo la validación cruzada especificando:
# - El dataset
# - Las variables de entrada y salida (fórmula)
# - La manera de crear los folds (además de cuántos)
# - La función de entrenamiento
# - la función de predicción

# Haciendo 100 repeticiones con de la VC, para evaluar si hay evidencia de que
# corrige autocorrelación espacial. Si así es, se espera que la densidad del
# error en cada fold espacial sea parecida.

# Si un fold resulta muy bien predicho, y esto coincide con un fold al que pertenecen no todos los datos de un arrecife, hay algo raro.

# Esto NO es cierto, lo que estas modas pueden indicar es la presencia de agregados
# (arrecifes u otro nivel), cuyas cobertura de acrópora palmata sigue patrones
# similares ante distintas variables captadas mediante percepción remota
# (puesto que autocorrelación espacial se está controlando a nivel, por ejemplo,
# de Limones al segmentarlo en distintos folds).

# Que haya folds muy mal predichos podría deberse a que es necesario hacer
# el análisis por agregados para mejorar la predicción.

# Esto sugiere un siguiente paso para este análisis: encontrar dichos agregados
# (Limones parece ser un caso promisorio), predecir la cobertura de coral mediante
# variables satelitales, evaluar el desempeño de este método en distintas fechas
# y con datos de campo apropiados, Si la predicción es promisoria, y las variables
# importantes se mantienen, se podría ir pensando en un método de homologación de
# imágenes satelitales para predecir con ellas y tener una manera de monitorear
# el arrecife reduciendo la cantidad de trabajo de campo realizado.

# Es una buena noticia encontrar estos agregados, porque quiere decir que la
# predicción se puede mejorar mucho a esos niveles, que la predicción global que
# se presenta en este artículo

# parsperrorest ya no jala con el nuevo R.
set.seed(12345)
cv_cat_latitud_5_rep_500 <- sperrorest(
  formula,
  data = df_trabajo_2010_variables_selectas,
  coords = c("longitud", "latitud"),
  model.fun = randomForest,
  pred.fun = predict,
  smp.fun = partition.factor,
  # La diferencia entre "partition.factor" y "partition.factor.cv" es que
  # la segunda toma folds como agregados aleatorios de la partición por
  # factores y la primera lo hace directamente sobre ésta.
  smp.args = list(
    fac = df_trabajo_2010_variables_selectas$cat_latitud_5,
    repetition = 1:500),
  # Para la paralelización, que ya no jala
  # par.args = list(
  #   par.units = 4,
  #   par.mode = 1),
  error.fold = TRUE,
  error.rep = TRUE,
  benchmark = TRUE,
  progress = 1)
saveRDS(cv_cat_latitud_5_rep_500, "../../productos/cv_cat_latitud_5_rep_500.RData")
cv_cat_latitud_5_rep_500 <- readRDS("../../productos/cv_cat_latitud_5_rep_500.RData")

# Revisando resultados

# Generales
summary(cv_cat_latitud_5_rep_500)

# Viendo la estructura para obtener el error
#str(cv_cat_latitud_5_rep_500, max.level = 2)

summary(cv_cat_latitud_5_rep_500$error.rep)
# Le va ligeramente mejor que a un modelo aleatorio:
# test.accuracy        0.5485502

#summary(cv_cat_latitud_5_rep_500$error.fold)
exactitudes_fold_latitud_5_rep_500 <-
  data_frame(
    exactitud = ((cv_cat_latitud_5_rep_500$error.fold %>%
        flatten() %>%
        transpose())[["test"]] %>%
        transpose())[["accuracy"]] %>%
      as.numeric()
  ) %>%
  mutate(
    nombre = rep(1:5, 500) %>%
      as.character()
  )

# Ploteando errores por fold.
ggplot(exactitudes_fold_latitud_5_rep_500,
  aes(x = exactitud, group = nombre, fill = nombre)) +
  geom_histogram(position = "identity", alpha = 0.7)

# Ver el caso de Limones, que existan sus datos en dos folds distintos y que
# se hayan predicho tan bien (relativamente), aún controlando por autocorrelación
# espacial dentro del mismo, sugiere que hay una posible relación entre variables
# satelitales y categorías de porcentaje de cobertura para ciertos agregados, que
# merece ser explotada.
k_folds_cat_latitud_5 <- partition.factor(df_trabajo_2010_variables_selectas, fac = df_trabajo_2010_variables_selectas$cat_latitud_5, repetition = 1:1)

plot(k_folds_cat_latitud_5, df_trabajo_2010_variables_selectas,
  coords = c("longitud","latitud"))

# Tabla de número de puntos por arrecife y 5-categoría de latitud.
df_trabajo_2010_variables_selectas %>%
  group_by(arrecife, cat_latitud_5) %>%
    # Obteniendo la media de la latitud dentro de cada grupo para ordenarlos por latitud
    summarise(
      latitud_media = mean(latitud),
      n = n()
    ) %>%
  arrange(latitud_media)
# Se ve como las clases 4 y 5, que son las que comparten muchos puntos de limones 
# son las mejor clasificadas.

### CV con deciles

set.seed(12345)
cv_cat_latitud_10_rep_500 <- sperrorest(
  formula,
  data = df_trabajo_2010_variables_selectas,
  coords = c("longitud", "latitud"),
  model.fun = randomForest,
  pred.fun = predict,
  smp.fun = partition.factor,
  # La diferencia entre "partition.factor" y "partition.factor.cv" es que
  # la segunda toma folds como agregados aleatorios de la partición por
  # factores y la primera lo hace directamente sobre ésta.
  smp.args = list(
    fac = df_trabajo_2010_variables_selectas$cat_latitud_10,
    repetition = 1:500),
  # Para la paralelización
  par.args = list(
    par.units = 4,
    par.mode = 1),
  error.fold = TRUE,
  error.rep = TRUE,
  benchmark = TRUE,
  progress = 1)
saveRDS(cv_cat_latitud_10_rep_500, "../../productos/cv_cat_latitud_10_rep_500.RData")
cv_cat_latitud_10_rep_500 <- readRDS("../../productos/cv_cat_latitud_10_rep_500.RData")

# Revisando resultados

# Generales
summary(cv_cat_latitud_10)

# Viendo la estructura para obtener el error
#str(cv_cat_latitud_10, max.level = 2)

summary(cv_cat_latitud_10$error.rep)
# Le va ligeramente mejor que a un modelo aleatorio:
# test.accuracy        0.5485502

#summary(cv_cat_latitud_10$error.fold)
exactitudes_fold_latitud_10_rep_500 <-
  data_frame(
    exactitud = ((cv_cat_latitud_10$error.fold %>%
        flatten() %>%
        transpose())[["test"]] %>%
        transpose())[["accuracy"]] %>%
      as.numeric()
  ) %>%
  mutate(
    nombre = rep(1:10, 100) %>%
      as.character()
  )

# Ploteando errores por fold.
ggplot(exactitudes_fold_latitud_10_rep_500,
  aes(x = exactitud, group = nombre, fill = nombre)) +
  geom_histogram(position = "identity", alpha = 0.7)

k_folds_cat_latitud_10 <- partition.factor(df_trabajo_2010_variables_selectas, repetition = 1:1, fac = "cat_latitud_10")

plot(k_folds_cat_latitud_10, df_trabajo_2010_variables_selectas,
  coords = c("longitud","latitud"))

# Tabla de número de puntos por arrecife y 5-categoría de latitud.
df_trabajo_2010_variables_selectas %>%
  group_by(arrecife, cat_latitud_10) %>%
    # Obteniendo la media de la latitud dentro de cada grupo para ordenarlos por latitud
    summarise(
      latitud_media = mean(latitud),
      n = n()
    ) %>%
  arrange(latitud_media)

# Frecuencias "cat_latitud_10" vs "cat_cobertura_acropora_2"
table(df_trabajo_2010_variables_selectas$cat_latitud_10, 
  df_trabajo_2010_variables_selectas$cat_cobertura_acropora_2)

# Frecuencias "arrecife" vs "cat_cobertura_acropora_2"
table(df_trabajo_2010_variables_selectas$arrecife, 
  df_trabajo_2010_variables_selectas$cat_cobertura_acropora_2)

# Nuevamente se ve cómo Limones, que ahora corresponde a 3 folds, es el que "salva"
# al modelo. La prominencia de Limones puede deberse a que tiene tantos puntos, que
# ese "agregado" puede ser muy bien representado en el modelo de predicción.

### CV con cuartiles

set.seed(12345)
cv_cat_latitud_4_rep_500 <- sperrorest(
  formula,
  data = df_trabajo_2010_variables_selectas,
  coords = c("longitud", "latitud"),
  model.fun = randomForest,
  pred.fun = predict,
  smp.fun = partition.factor,
  # La diferencia entre "partition.factor" y "partition.factor.cv" es que
  # la segunda toma folds como agregados aleatorios de la partición por
  # factores y la primera lo hace directamente sobre ésta.
  smp.args = list(
    fac = df_trabajo_2010_variables_selectas$cat_latitud_4,
    repetition = 1:500),
  # Para la paralelización
  # par.args = list(
  #   par.units = 4,
  #   par.mode = 1),
  error.fold = TRUE,
  error.rep = TRUE,
  benchmark = TRUE,
  progress = 1)

# Revisando resultados

# Generales
summary(cv_cat_latitud_4_rep_500)

# Viendo la estructura para obtener el error
#str(cv_cat_latitud_10, max.level = 2)

summary(cv_cat_latitud_4_rep_500$error.rep)
# Le va ligeramente mejor que a un modelo aleatorio:
# test.accuracy        0.5214041

#summary(cv_cat_latitud_4_rep_500$error.fold)
exactitudes_fold_latitud_4_rep_500 <-
  data_frame(
    exactitud = ((cv_cat_latitud_4_rep_500$error.fold %>%
        flatten() %>%
        transpose())[["test"]] %>%
        transpose())[["accuracy"]] %>%
      as.numeric()
  ) %>%
  mutate(
    nombre = rep(1:4, 100) %>%
      as.character()
  )

# Ploteando errores por fold.
ggplot(exactitudes_fold_latitud_4_rep_500,
  aes(x = exactitud, group = nombre, fill = nombre)) +
  geom_histogram(position = "identity", alpha = 0.7)

k_folds_cat_latitud_4 <- partition.factor(df_trabajo_2010_variables_selectas, repetition = 1:1, fac = "cat_latitud_4")

plot(k_folds_cat_latitud_4, df_trabajo_2010_variables_selectas,
  coords = c("longitud","latitud"))

# Tabla de número de puntos por arrecife y 4-categoría de latitud.
df_trabajo_2010_variables_selectas %>%
  group_by(arrecife, cat_latitud_4) %>%
    # Obteniendo la media de la latitud dentro de cada grupo para ordenarlos por latitud
    summarise(
      latitud_media = mean(latitud),
      n = n()
    ) %>%
  arrange(latitud_media)

# Frecuencias "cat_latitud_10" vs "cat_cobertura_acropora_2"
table(df_trabajo_2010_variables_selectas$cat_latitud_4, 
  df_trabajo_2010_variables_selectas$cat_cobertura_acropora_2)

# Frecuencias "arrecife" vs "cat_cobertura_acropora_2"
table(df_trabajo_2010_variables_selectas$arrecife, 
  df_trabajo_2010_variables_selectas$cat_cobertura_acropora_2)

# Nuevamente se ve cómo Limones, que ahora corresponde a 3 folds, es el que "salva"
# al modelo. La prominencia de Limones puede deberse a que tiene tantos puntos, que
# ese "agregado" puede ser muy bien representado en el modelo de predicción.
```

```{r, warning=FALSE, message=FALSE}
# cv_k_folds_cat_latitud_5_importancia_variables <- parsperrorest(
#   formula,
#   data = df_trabajo_2010_variables_selectas,
#   coords = c("longitud", "latitud"),
#   model.fun = randomForest,
#   pred.fun = predict,
#   smp.fun = partition.factor.cv,
#   smp.args = list(
#     fac = "cat_latitud_5",
#     repetition = 1:4,
#     nfold = 5,
#     seed1 = 123),
#   par.args = list(
#     par.units = 4,
#     par.mode = 1),
#   error.fold = TRUE,
#   error.rep = TRUE,
#   err.train = TRUE, # por curiosidad
#   benchmark = TRUE,
#   importance = TRUE, # muy tardada, pero útil.
#   imp.permutations = 200,
#   progress = 1)
# saveRDS(cv_k_folds_cat_latitud_5_importancia_variables,
# "../../productos/cv_k_folds_cat_latitud_5_importancia_variables.RData")
cv_k_folds_cat_latitud_5_importancia_variables <-
  readRDS("../../productos/cv_k_folds_cat_latitud_5_importancia_variables.RData")

# Viendo las variables más importantes:
summary(cv_k_folds_cat_latitud_5_importancia_variables$importance) %>%
  mutate(
    variables = row.names(.)
  ) %>%
  select(
    variables,
    everything()
  ) %>%
  arrange(desc(mean.error)) %>%
  select(
    variables,
    mean.error
  )

# Vector con las 1000 exactitudes para graficar su distribución vs la de un modelo aleatorio
exactitudes_cv_k_folds_cat_latitud_5 <- cv_k_folds_cat_latitud_5$error.rep$test.accuracy
```

```{r, warning=FALSE, message=FALSE}
# Prueba rápida con un modelo al azar:
# nrow(df_trabajo_2010_variables_selectas) # 876
# Simulemos la distribución del ECM al correr 1000 simulaciones de un etiquetado
# al azar de 876 registros (cantidad clasificada con Validación Cruzada)
# Sabemos que el modelo al azar sería la opción trivial más acertada puesto que
# hay la misma cantidad de registros con en cada categoría (por lo que no se puede,
# usar la moda, a diferencia si, por ejemplo, una categoría tuviera 90 registros y
# otra 10.

simulacion_error_azar <- ldply(1:10000, function(i){
  # TRUE: bien clasificado, FALSE: mal clasificado.
  muestra <- sample(x = c(TRUE, FALSE),
    size = nrow(df_trabajo_2010_variables_selectas),
    replace = TRUE,
    prob = c(0.5, 0.5))
  
  resultado <- data_frame(
    i = i,
    clasificacion_correcta = muestra
    )
  return(resultado)
  }) %>%
  group_by(i) %>%
  summarise(
    porcentaje_exito = sum(clasificacion_correcta)/n()
  ) %>%
  ungroup()

plot_distribuciones_aleatorio_rf <- simulacion_error_azar %>%
  mutate(
    tipo = "Clasificación al azar"
  ) %>%
  union(
    data_frame(
      i = 1:length(exactitudes_cv_k_folds_cat_latitud_5),
      porcentaje_exito = exactitudes_cv_k_folds_cat_latitud_5,
      tipo = "RandomForest variables satelitales"
    )
  )

ggplot(plot_distribuciones_aleatorio_rf,
  aes(x = porcentaje_exito, fill = tipo, group = tipo)) +
  geom_histogram(position="identity", alpha = 0.8)

ggplot(plot_distribuciones_aleatorio_rf,
  aes(x = tipo, y = porcentaje_exito)) +
  geom_boxplot()

# Calculando el p-value del percentil 5 de "RandomForest variables satelitales"
# con respecto a "Clasificación al azar"
percentil_5 <- quantile(exactitudes_cv_k_folds_cat_latitud_5, probs = 0.05)
p_value <- simulacion_error_azar %>%
  filter_(paste0("porcentaje_exito >= ", percentil_5)) %>%
  summarise(
    p_value = n()/nrow(simulacion_error_azar)
  ) %>%
  '$'(., p_value)
```

Conclusiones:
- Limones se comporta "diferente" a los otros arrecifes (ver 4-fold vs 5/10 fold),
- Sin embargo, aún controlando por autocorrelación espacial, Limones posiblemente pueda considerarse como un "agregado" cuyas cobertura de acrópora se pueda estimar
razonablemente bien mediante imágenes satelitales, al hacer un análisis específico
para él.
- Se puede buscar la existencia de otros agregados.
- Si todo sale bien (se encuentran agregados con la misma relación entre variables de percepción remota y cobertura de acrópora, al controlar la autocorrelación espacial), se podría entrenar un modelo para cada uno de ellos en determinada fecha, validarlo sobre distintos fechas con datos de campo (homologando variables satelitales), y si pasa las validaciones, usarlo para predecir cobertura de
acrópora mediante imágenes satelitales.
- Controlar por autocorrelación espacial es muy necesario para la generalización
de los modelos (si no lo hacemos, quién nos asegura que nuestro modelo predice
cobertura muy bien porque "delineó" los cuadritos existentes de cobertura, ¿y en
realidad está usando la información espacial para estimar latitud y longitud?)

Pasos futuros a considerar:
- Considerar el aspecto como una variable circular 0º = 360º, en especial para
 calcular su media y desviación estándar, que se ve que es una variable potencialmente significativa.
 - Usar features para hacer deep learning (ajuste de redes neuronales convolucionadas).
 - Hablar con expertos para que probar otras variables remotas potencialmente útiles
 para la predicción de A. palmata.

Sergio:
1. Me ofrece los viáticos del Mau.
2. Por experiencia del Mau, me va a estar fregando por eso para siempre. Es un anzuelo.
3. Mejor le digo a Lorenzo que si me consigue para el avión y lo que sea para la comida ya la armamos.
```{r}
# Haciendo 10000 repeticiones de la validación cruzada para obtener la distribución del error
# Las repeticiones son paralelizadas en los 4 núcleos de la compu.
cv_k_folds_cat_latitud_5 <- parsperrorest(
  formula,
  data = df_trabajo_2010_variables_selectas,
  coords = c("longitud", "latitud"),
  model.fun = randomForest,
  pred.fun = predict,
  smp.fun = partition.factor.cv,
  smp.args = list(
    fac = "cat_latitud_5",
    repetition = 1:10000,
    nfold = 5,
    seed1 = 123),
  par.args = list(
    par.units = 4,
    par.mode = 1),
  error.fold = TRUE,
  error.rep = TRUE,
  benchmark = TRUE,
  progress = 1)
# saveRDS(cv_k_folds_cat_latitud_5,
#   "../../productos/cv_k_folds_cat_latitud_5.RData")
```